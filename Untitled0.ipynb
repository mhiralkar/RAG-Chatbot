!pip install google-generativeai chromadb sentence-transformers streamlit fastapi uvicorn langchain

import google.generativeai as genai
import json

# Setting up Gemini API key
GENAI_API_KEY = "AIzaSyBriDLi4mq65NsPpjlhUOJrKSK0hpwqwk4"
genai.configure(api_key=GENAI_API_KEY)

# Now we have to define customer segments
segments = {
    "Loyal Customers": ["High Spenders", "Frequent Visitors"],
    "Casual Customers": ["Weekend Diners", "Occasional Visitors"],
    "Discount Seekers": ["Coupon Users", "Happy Hour Customers"],
    "Health-Conscious Customers": ["Organic Eaters", "Low-Calorie Seekers"]
}

# Define the function to generate insights
def generate_insights(segment, sub_segment):
    prompt = f"""
    Generate a customer analysis report for a fast-food chain.
    Segment: {segment}
    Sub-segment: {sub_segment}
    
    Provide:
    - Demographics
    - Visit frequency & spending habits
    - Revenue impact (percentage of total sales)
    - Engagement strategies
    """

    model = genai.GenerativeModel("gemini-pro")
    response = model.generate_content(prompt)
    
    return response.text  # Get the generated response as text

# We have to create the Generate reports
reports = {}
for segment, sub_segments in segments.items():
    reports[segment] = {}
    for sub_segment in sub_segments:
        reports[segment][sub_segment] = generate_insights(segment, sub_segment)

# Save to JSON file
with open("customer_segmentation_reports.json", "w") as f:
    json.dump(reports, f, indent=4)

print("âœ… Synthetic reports generated and saved as JSON!")


import json
import chromadb
from sentence_transformers import SentenceTransformer

# Load the data
with open("customer_segmentation_reports.json", "r") as f:
    reports = json.load(f)

# Initialize ChromaDB
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_or_create_collection(name="customer_segments")

# Initialize sentence transformer model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Process and store in ChromaDB
for segment, sub_segments in reports.items():
    for sub_segment, content in sub_segments.items():
        embedding = model.encode(content).tolist()
        collection.add(
            ids=[f"{segment}-{sub_segment}"],
            embeddings=[embedding],
            metadatas=[{"segment": segment, "sub_segment": sub_segment, "text": content}]
        )

print("âœ… Data stored in ChromaDB!")


import google.generativeai as genai
import chromadb
from sentence_transformers import SentenceTransformer

# Set up Gemini API key
GENAI_API_KEY = "AIzaSyBriDLi4mq65NsPpjlhUOJrKSK0hpwqwk4"
genai.configure(api_key=GENAI_API_KEY)

# Initialize ChromaDB
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_collection(name="customer_segments")

# Initialize sentence transformer model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Function to retrieve relevant context
def retrieve_context(query):
    query_embedding = model.encode(query).tolist()
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=3  # Retrieve top 3 most relevant segments
    )
    
    # Extract text from retrieved metadata
    return [doc["text"] for doc in results["metadatas"][0]]

# Function to generate a response using Google Gemini API
def generate_response(query):
    context = retrieve_context(query)
    
    prompt = f"""
    Context: {context}
    User Question: {query}
    
    Provide a clear and concise answer based on the provided context.
    """

    model = genai.GenerativeModel("gemini-pro")
    response = model.generate_content(prompt)
    
    return response.text  # Correct way to retrieve generated text

# Example usage
query = "Which segment responds best to discounts?"
print("ðŸ¤– Chatbot Response:", generate_response(query))


%%writefile app.py
import streamlit as st
import google.generativeai as genai
import chromadb
from sentence_transformers import SentenceTransformer

# Set up Gemini API (Replace with your actual API key)
GENAI_API_KEY = "AIzaSyBriDLi4mq65NsPpjlhUOJrKSK0hpwqwk4"
genai.configure(api_key=GENAI_API_KEY)

# Initialize ChromaDB
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_collection(name="customer_segments")

# Initialize embedding model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Function to retrieve relevant context
def retrieve_context(query):
    query_embedding = model.encode(query).tolist()
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=3  # Retrieve top 3 results
    )
    return [doc["text"] for doc in results["metadatas"][0]]

# Function to generate a response
def generate_response(query):
    context = retrieve_context(query)
    prompt = f"""
    Context: {context}
    User Question: {query}
    
    Answer the user's question based on the context.
    """

    model = genai.GenerativeModel("gemini-pro")
    response = model.generate_content(prompt)
    return response.text  # Correct way to retrieve generated text

st.title("Fast-Food Customer Segmentation Chatbot")

query = st.text_input("Ask a question:")
if st.button("Get Answer"):
    if query:
        response = generate_response(query)
        st.write("ðŸ¤– Chatbot:", response)
    else:
        st.warning("Please enter a question.")


!streamlit run app.py --server.port 8501 & sleep 5

import time
from pyngrok import ngrok

# Start Streamlit in the background
!nohup streamlit run app.py --server.port 8501 &

# Wait for Streamlit to initialize
time.sleep(5)

# Set ngrok auth token (Here i have to add the auth token)
ngrok.set_auth_token("2t6wZqsReqFOsdqEM3LMhyBbhc5_5kSyN4TTSF5AfyzvLwkhL")

# Start ngrok tunnel
public_url = ngrok.connect(8501)
print("Streamlit app is accessible at:", public_url)
